{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Attaching package: ‘data.table’\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "Loading required package: Hmisc\n",
      "Loading required package: lattice\n",
      "Loading required package: survival\n",
      "Loading required package: Formula\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Attaching package: ‘Hmisc’\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    combine, src, summarize\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    format.pval, round.POSIXt, trunc.POSIXt, units\n",
      "\n",
      "Loading required package: SparseM\n",
      "\n",
      "Attaching package: ‘SparseM’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    backsolve\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data processing script\n",
    "# \n",
    "# assign working directory path\n",
    "wd.path <- \"~/in\"\n",
    "setwd(wd.path)\n",
    "set.seed(1234)\n",
    "library(dplyr)\n",
    "library(data.table)            # to get fread\n",
    "# library(foreach)\n",
    "# library(caret)\n",
    "# library(reshape2)\n",
    "library(rms)\n",
    "library(WeightedROC)\n",
    "\n",
    "#Sample mode function from Source: https://stackoverflow.com/questions/2547402/is-there-a-built-in-function-for-finding-the-mode\n",
    "Mode <- function(x, na.rm = FALSE) {\n",
    "  if (na.rm) {\n",
    "    x = x[!is.na(x)]\n",
    "  }\n",
    "  \n",
    "  ux <- unique(x)\n",
    "  return(ux[which.max(tabulate(match(x, ux)))])\n",
    "}\n",
    "\n",
    "imputationFunction <- function(imputeToData, imputeFromData, FUN, missingCols, suffix){\n",
    "  # imputeToData -  Imputation to be done on this data\n",
    "  # imputeFromData - Imputations calculation from this data\n",
    "  # FUN - imputation function\n",
    "  # missingCols - missing value column names\n",
    "  # suffix - suffix to add after column name\n",
    "  \n",
    "  imputeToData <- imputeToData[, names(imputeToData) %in% missingCols]\n",
    "  imputeFromData <- imputeFromData[, names(imputeFromData) %in% missingCols]\n",
    "  imputeVec <- apply(imputeFromData, 2, function(x) FUN(x, na.rm = T))\n",
    "  \n",
    "  for (i in 1:length(missingCols)) {\n",
    "    imputeToxData[is.na(imputeToData[, names(imputeToData) %in% missingCols[i]])\n",
    "                 , names(imputeToData) %in% missingCols[i]] <- imputeVec[names(imputeVec) %in% missingCols[i]]\n",
    "  }\n",
    "  \n",
    "  names(imputeToData) <- paste0(names(imputeToData), suffix)\n",
    "  return(imputeToData)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a small sample dataset to test the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_row = 1000                                                 # number of rows to take in the sample\n",
    "num.impute = 1                                                  # number of imputations to perform on each node \n",
    "feat_list = c('SK_ID_CURR','TARGET','fold','Weights',\n",
    "              \n",
    "              \n",
    "'Avg_EXT_SOURCE_application',\n",
    "'ANNUITY_LENGTH',\n",
    "'MAX_DAYS_CREDIT_bureau',\n",
    "'CNT_INSTALMENT_FUTURE_min_sd_POS_CASH',\n",
    "'MAX_DAYS_CREDIT_ENDDATE_bureau',\n",
    "'CODE_GENDER',\n",
    "'CREDIT_TO_GOODS_RATIO',\n",
    "'EXT_SOURCE_1.x',\n",
    "'EXT_SOURCE_2.x',\n",
    "'EXT_SOURCE_3.x'              \n",
    ")\n",
    "\n",
    "requested_formula = ~ TARGET +Avg_EXT_SOURCE_application + ANNUITY_LENGTH + MAX_DAYS_CREDIT_bureau + \n",
    "    CNT_INSTALMENT_FUTURE_min_sd_POS_CASH + MAX_DAYS_CREDIT_ENDDATE_bureau + \n",
    "    CODE_GENDER + CREDIT_TO_GOODS_RATIO + EXT_SOURCE_1.x + EXT_SOURCE_2.x + \n",
    "    EXT_SOURCE_3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"2018-08-28 22:56:50 UTC\"\n",
      "Read 1000 rows and 3205 (of 3205) columns from 4.639 GB file in 00:00:04\n",
      "[1] \"2018-08-28 22:57:47 UTC\"\n"
     ]
    }
   ],
   "source": [
    "print(Sys.time())\n",
    "train <- fread('train_modified.csv', nrows=samp_row) # applications test data\n",
    "test <- fread('test_modified.csv', nrows=samp_row) # applications train data\n",
    "print(Sys.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"2018-08-28 22:57:47 UTC\"\n",
      "[1] \"2018-08-28 22:57:48 UTC\"\n",
      "[1] \"2018-08-28 22:57:48 UTC\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.006   0.001   0.007 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"2018-08-28 22:57:48 UTC\"\n"
     ]
    }
   ],
   "source": [
    "train_imp <- train[,feat_list,with=FALSE]\n",
    "print(Sys.time())\n",
    "\n",
    "test_imp <- test\n",
    "test_imp$fold <- rep(NA,nrow(test_imp))\n",
    "test_imp$Weights <- rep(NA,nrow(test_imp))\n",
    "test_imp$TARGET <- rep(NA,nrow(test_imp))\n",
    "test_imp <- test_imp[, feat_list, with=FALSE]\n",
    "print(Sys.time())\n",
    "\n",
    "M <- rbind(train_imp, test_imp)\n",
    "M[M == 'XNA' | M == 'Unknown'] <- NA\n",
    "M = droplevels(M)\n",
    "print(Sys.time())\n",
    "\n",
    "# replace Inf with NA as transcan, aregimpute cannot handle Inf\n",
    "system.time(invisible(lapply(names(M),function(.name) set(M, which(is.infinite(M[[.name]])), j = .name,value =NA))))\n",
    "print(Sys.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"2018-08-28 22:59:41 UTC\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'rms'</li>\n",
       "\t<li>'SparseM'</li>\n",
       "\t<li>'Hmisc'</li>\n",
       "\t<li>'ggplot2'</li>\n",
       "\t<li>'Formula'</li>\n",
       "\t<li>'survival'</li>\n",
       "\t<li>'lattice'</li>\n",
       "\t<li>'RevoUtils'</li>\n",
       "\t<li>'stats'</li>\n",
       "\t<li>'graphics'</li>\n",
       "\t<li>'grDevices'</li>\n",
       "\t<li>'utils'</li>\n",
       "\t<li>'datasets'</li>\n",
       "\t<li>'RevoUtilsMath'</li>\n",
       "\t<li>'methods'</li>\n",
       "\t<li>'base'</li>\n",
       "</ol>\n",
       "</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'rms'\n",
       "\\item 'SparseM'\n",
       "\\item 'Hmisc'\n",
       "\\item 'ggplot2'\n",
       "\\item 'Formula'\n",
       "\\item 'survival'\n",
       "\\item 'lattice'\n",
       "\\item 'RevoUtils'\n",
       "\\item 'stats'\n",
       "\\item 'graphics'\n",
       "\\item 'grDevices'\n",
       "\\item 'utils'\n",
       "\\item 'datasets'\n",
       "\\item 'RevoUtilsMath'\n",
       "\\item 'methods'\n",
       "\\item 'base'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 1. 'rms'\n",
       "2. 'SparseM'\n",
       "3. 'Hmisc'\n",
       "4. 'ggplot2'\n",
       "5. 'Formula'\n",
       "6. 'survival'\n",
       "7. 'lattice'\n",
       "8. 'RevoUtils'\n",
       "9. 'stats'\n",
       "10. 'graphics'\n",
       "11. 'grDevices'\n",
       "12. 'utils'\n",
       "13. 'datasets'\n",
       "14. 'RevoUtilsMath'\n",
       "15. 'methods'\n",
       "16. 'base'\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       " [1] \"rms\"           \"SparseM\"       \"Hmisc\"         \"ggplot2\"      \n",
       " [5] \"Formula\"       \"survival\"      \"lattice\"       \"RevoUtils\"    \n",
       " [9] \"stats\"         \"graphics\"      \"grDevices\"     \"utils\"        \n",
       "[13] \"datasets\"      \"RevoUtilsMath\" \"methods\"       \"base\"         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Finished Imputation on all clusters.\"\n",
      "[1] \"2018-08-28 23:00:05 UTC\"\n",
      "[1] \"Finished Imputing the datasets\"\n",
      "[1] \"2018-08-28 23:00:05 UTC\"\n"
     ]
    }
   ],
   "source": [
    "print(Sys.time())\n",
    "\n",
    "library(parallel)\n",
    "# Using all cores can slow down the computer\n",
    "# significantly, I therefore try to leave one\n",
    "# core alone in order to be able to do something \n",
    "# else during the time the code runs\n",
    "\n",
    "# cores_2_use <- detectCores() - 1\n",
    "cores_2_use <- 1\n",
    "\n",
    "cl <- makeCluster(cores_2_use)\n",
    "clusterSetRNGStream(cl, 9956)\n",
    "\n",
    "clusterExport(cl, c(\"M\", \"num.impute\", \"requested_formula\"))   # specify the list of objects to pass to each thread\n",
    "clusterEvalQ(cl, library(rms))\n",
    "imp_pars <- \n",
    "  parLapply(cl = cl, X = 1:cores_2_use, fun = function(no){\n",
    "    mi <- aregImpute(requested_formula\n",
    "                 , data=M, n.impute=num.impute, nk=4, pr=FALSE)\n",
    "  })\n",
    "stopCluster(cl)\n",
    "print(\"Finished Imputation on all clusters.\")\n",
    "print(Sys.time())\n",
    "\n",
    "setDF(M)             # converting the Data Table back to Data Frame, otherwise the join would not work \n",
    "\n",
    "completed.data = list()\n",
    "for (i in 1:length(imp_pars)){\n",
    "    for (j in 1:num.impute){\n",
    "        imputed.data <- impute.transcan(imp_pars[[i]],imputation=j,data=M,list.out=TRUE,pr=FALSE,check=FALSE)\n",
    "        k = (i-1)*num.impute + j\n",
    "        completed.data[[k]] <- M\n",
    "        completed.data[[k]][names(imputed.data)] <- imputed.data\n",
    "        }\n",
    "}\n",
    "print(\"Finished Imputing the datasets\")\n",
    "print(Sys.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- completed.data[[1]][!is.na(completed.data[[1]]$Weights),]\n",
    "test <- completed.data[[1]][is.na(completed.data[[1]]$Weights),]\n",
    "string_formula <- TARGET ~ +rcs(Avg_EXT_SOURCE_application, 4) + rcs(ANNUITY_LENGTH, \n",
    "    4) + MAX_DAYS_CREDIT_bureau + rcs(CNT_INSTALMENT_FUTURE_min_sd_POS_CASH, \n",
    "    4) + rcs(MAX_DAYS_CREDIT_ENDDATE_bureau, 4) + CODE_GENDER + \n",
    "    rcs(CREDIT_TO_GOODS_RATIO, 4) + rcs(EXT_SOURCE_1.x, 4) + \n",
    "    rcs(EXT_SOURCE_2.x, 4) + rcs(EXT_SOURCE_3.x, 4)\n",
    "requested_formula = as.formula(string_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in lrm(data = trainData, formula = requested_formula, weight = Weights, :\n",
      "“currently weights are ignored in model validation and bootstrapping lrm fits”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          index.orig training    test optimism index.corrected  n\n",
      "Dxy           0.4753   0.7628  0.6288   0.1340          0.3413 10\n",
      "R2            0.5861   0.3644  0.2102   0.1542          0.4319 10\n",
      "Intercept     0.0000   0.0000 -0.6482   0.6482         -0.6482 10\n",
      "Slope         1.0000   1.0000  0.6158   0.3842          0.6158 10\n",
      "Emax          0.0000   0.0000  0.2492   0.2492          0.2492 10\n",
      "D             0.0206   0.1563  0.0890   0.0673         -0.0467 10\n",
      "U            -0.0025  -0.0025  0.0253  -0.0278          0.0253 10\n",
      "Q             0.0230   0.1587  0.0637   0.0950         -0.0720 10\n",
      "B             0.0811   0.0493  0.0610  -0.0117          0.0928 10\n",
      "g             9.8827   3.1927  1.8595   1.3332          8.5495 10\n",
      "gp            0.1210   0.1009  0.0832   0.0176          0.1034 10\n",
      "[1] 0.3866744\n",
      "[1] 0.5483333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in lrm(data = trainData, formula = requested_formula, weight = Weights, :\n",
      "“currently weights are ignored in model validation and bootstrapping lrm fits”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          index.orig training    test optimism index.corrected  n\n",
      "Dxy           0.4355   0.6866  0.5692   0.1174          0.3181 10\n",
      "R2            0.3049   0.2944  0.1887   0.1057          0.1992 10\n",
      "Intercept     0.0000   0.0000 -0.5528   0.5528         -0.5528 10\n",
      "Slope         1.0000   1.0000  0.7320   0.2680          0.7320 10\n",
      "Emax          0.0000   0.0000  0.1878   0.1878          0.1878 10\n",
      "D             0.0051   0.1275  0.0783   0.0491         -0.0441 10\n",
      "U            -0.0025  -0.0025  0.0084  -0.0110          0.0084 10\n",
      "Q             0.0076   0.1300  0.0699   0.0601         -0.0525 10\n",
      "B             0.0647   0.0545  0.0602  -0.0057          0.0704 10\n",
      "g             3.2482   2.0341  1.4748   0.5593          2.6890 10\n",
      "gp            0.0666   0.0955  0.0774   0.0180          0.0486 10\n",
      "[1] 0.328137\n",
      "[1] 0.7588462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in lrm(data = trainData, formula = requested_formula, weight = Weights, :\n",
      "“currently weights are ignored in model validation and bootstrapping lrm fits”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          index.orig training    test optimism index.corrected  n\n",
      "Dxy           0.3523   0.6428  0.5075   0.1353          0.2170 10\n",
      "R2            0.4632   0.2597  0.1295   0.1302          0.3330 10\n",
      "Intercept     0.0000   0.0000 -0.8376   0.8376         -0.8376 10\n",
      "Slope         1.0000   1.0000  0.6183   0.3817          0.6183 10\n",
      "Emax          0.0000   0.0000  0.2953   0.2953          0.2953 10\n",
      "D             0.0155   0.1046  0.0494   0.0552         -0.0397 10\n",
      "U            -0.0024  -0.0024  0.0177  -0.0202          0.0177 10\n",
      "Q             0.0179   0.1070  0.0317   0.0754         -0.0574 10\n",
      "B             0.0660   0.0503  0.0563  -0.0059          0.0720 10\n",
      "g             3.3500   2.0526  1.2083   0.8442          2.5057 10\n",
      "gp            0.0935   0.0822  0.0598   0.0224          0.0712 10\n",
      "[1] 0.490098\n",
      "[1] 0.5636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in lrm(data = trainData, formula = requested_formula, weight = Weights, :\n",
      "“currently weights are ignored in model validation and bootstrapping lrm fits”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          index.orig training    test optimism index.corrected  n\n",
      "Dxy           0.2904   0.6625  0.5156   0.1469          0.1435 10\n",
      "R2            0.4686   0.2720  0.1527   0.1193          0.3493 10\n",
      "Intercept     0.0000   0.0000 -0.6815   0.6815         -0.6815 10\n",
      "Slope         1.0000   1.0000  0.6776   0.3224          0.6776 10\n",
      "Emax          0.0000   0.0000  0.2361   0.2361          0.2361 10\n",
      "D             0.0170   0.1172  0.0625   0.0547         -0.0377 10\n",
      "U            -0.0026  -0.0026  0.0126  -0.0152          0.0126 10\n",
      "Q             0.0196   0.1197  0.0499   0.0699         -0.0503 10\n",
      "B             0.0759   0.0563  0.0611  -0.0047          0.0806 10\n",
      "g             4.1506   1.9142  1.2744   0.6399          3.5107 10\n",
      "gp            0.0963   0.0930  0.0701   0.0228          0.0735 10\n",
      "[1] 0.5767188\n",
      "[1] 0.6138072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in lrm(data = trainData, formula = requested_formula, weight = Weights, :\n",
      "“currently weights are ignored in model validation and bootstrapping lrm fits”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          index.orig training    test optimism index.corrected  n\n",
      "Dxy           0.3964   0.7668  0.6238   0.1430          0.2534 10\n",
      "R2            0.5276   0.3597  0.2091   0.1506          0.3770 10\n",
      "Intercept     0.0000   0.0000 -0.6949   0.6949         -0.6949 10\n",
      "Slope         1.0000   1.0000  0.6384   0.3616          0.6384 10\n",
      "Emax          0.0000   0.0000  0.2526   0.2526          0.2526 10\n",
      "D             0.0185   0.1489  0.0834   0.0655         -0.0469 10\n",
      "U            -0.0025  -0.0025  0.0254  -0.0279          0.0254 10\n",
      "Q             0.0210   0.1514  0.0580   0.0934         -0.0724 10\n",
      "B             0.0772   0.0479  0.0546  -0.0067          0.0839 10\n",
      "g             5.0370   2.9184  1.6843   1.2341          3.8029 10\n",
      "gp            0.1269   0.0958  0.0764   0.0194          0.1075 10\n",
      "[1] 0.4519207\n",
      "[1] 0.5276989\n"
     ]
    }
   ],
   "source": [
    "#Perform 5 fold cross validation\n",
    "model = list()\n",
    "mod_anova = list()\n",
    "test_roc = list()\n",
    "\n",
    "for(i in 1:5){\n",
    "    testData <- train[train$fold==i,]\n",
    "    trainData <- train[train$fold!=i,]\n",
    "    \n",
    "\n",
    "    a_model = lrm(data=trainData, formula = requested_formula, weight=Weights, tol=1E-8,\n",
    "                  x=TRUE,y=TRUE)\n",
    "        \n",
    "    # diagnostic plots\n",
    "    ## Variable Importance\n",
    "    mod_anova[[i]] <- anova(a_model)\n",
    "    \n",
    "    ## Validation Statistics\n",
    "    print(validate(a_model, B=10))\n",
    "    model[[i]] <- a_model\n",
    "\n",
    "    ## Calibration Curve\n",
    "    # plot(calibrate(a_model, B=10))\n",
    "\n",
    "    # use a fitted model to score a dataset, convert score to probability\n",
    "    test_scored <- cbind(testData, predict(a_model, testData, se.fit=TRUE))\n",
    "    test_scored$pred = exp(test_scored$linear.predictors)/(1+exp(test_scored$linear.predictors))\n",
    "\n",
    "    # Weighted AUROC\n",
    "    tp.fp <- WeightedROC(test_scored$pred,test_scored$TARGET,test_scored$Weights)\n",
    "    test_roc[[i]] <- WeightedAUC(tp.fp)\n",
    "    print(test_roc[[i]])\n",
    "\n",
    "    # Unweighted AUROC\n",
    "    tp.fp <- WeightedROC(test_scored$pred,test_scored$TARGET)\n",
    "    print(WeightedAUC(tp.fp))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Are the imputation from the different cores giving rise to the same datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(parallel)\n",
    "# Using all cores can slow down the computer\n",
    "# significantly, I therefore try to leave one\n",
    "# core alone in order to be able to do something \n",
    "# else during the time the code runs\n",
    "\n",
    "#cores_2_use <- detectCores() - 1\n",
    "cores_2_use <- 2\n",
    "num.impute <- 2\n",
    "\n",
    "cl <- makeCluster(cores_2_use)\n",
    "clusterSetRNGStream(cl, 9956)\n",
    "\n",
    "clusterExport(cl, c(\"M\", \"num.impute\"))   # specify the list of objects to pass to each thread\n",
    "clusterEvalQ(cl, library(rms))\n",
    "imp_pars <- \n",
    "  parLapply(cl = cl, X = 1:cores_2_use, fun = function(no){\n",
    "    mi <- aregImpute(~ TARGET +Avg_EXT_SOURCE_application + ANNUITY_LENGTH + MAX_DAYS_CREDIT_bureau + \n",
    "    CNT_INSTALMENT_FUTURE_min_sd_POS_CASH\n",
    "                 , data=M, n.impute=num.impute, nk=4, pr=FALSE)\n",
    "  })\n",
    "stopCluster(cl)\n",
    "\n",
    "completed.data = list()\n",
    "for (i in 1:length(imp_pars)){\n",
    "    for (j in 1:num.impute){\n",
    "        imputed.data <- impute.transcan(imp_pars[[i]],imputation=j,data=M,list.out=TRUE,pr=FALSE,check=FALSE)\n",
    "        k = (i-1)*num.impute + j\n",
    "        completed.data[[k]] <- M\n",
    "        completed.data[[k]][names(imputed.data)] <- imputed.data\n",
    "        }\n",
    "}\n",
    "\n",
    "print(\"Variables that have any missing in completed.data.1\")\n",
    "names(completed.data[[1]])[apply(completed.data[[1]], 2, function(x) sum(is.na(x))) > 0]\n",
    "\n",
    "print(\"Variables that have any missing in completed.data.2\")\n",
    "names(completed.data[[2]])[apply(completed.data[[2]], 2, function(x) sum(is.na(x))) > 0]\n",
    "\n",
    "print(\"Are the two completions identical?\")\n",
    "identical(x=completed.data[[1]], y=completed.data[[2]])\n",
    "\n",
    "print(\"Three sample imputed values for MAX_DAYS_CREDIT_bureau, imputation 1 on Core 1\")\n",
    "print(imp_pars[[1]]$imputed$MAX_DAYS_CREDIT_bureau[1:3,1])\n",
    "print(\"Three sample imputed values for MAX_DAYS_CREDIT_bureau, imputation 1 on Core 2\")\n",
    "print(imp_pars[[2]]$imputed$MAX_DAYS_CREDIT_bureau[1:3,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the memory usage of each item\n",
    "sort(sapply(ls(), function(x) format(object.size(get(x)), unit = 'auto')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET ~ +Avg_EXT_SOURCE_application + ANNUITY_LENGTH + MAX_DAYS_CREDIT_bureau + \n",
      "    CNT_INSTALMENT_FUTURE_min_sd_POS_CASH + MAX_DAYS_CREDIT_ENDDATE_bureau + \n",
      "    CODE_GENDER + CREDIT_TO_GOODS_RATIO + EXT_SOURCE_1.x + EXT_SOURCE_2.x + \n",
      "    EXT_SOURCE_3.x\n"
     ]
    }
   ],
   "source": [
    "# Mechanically create a formula for imputation\n",
    "\n",
    "col_set = M %>% names()\n",
    "col_set = col_set[!col_set %in% c(\"TARGET\", 'SK_ID_CURR', 'fold', 'Weights')]\n",
    "\n",
    "string_formula = \"TARGET~\"\n",
    "for(i in col_set){\n",
    "  if(class(M[[i]]) == \"numeric\"){\n",
    "    tmp_component = paste0(\"+\",i)\n",
    "  }\n",
    "  if(class(M[[i]]) != \"numeric\"){\n",
    "    tmp_component = paste0(\"+\",i)\n",
    "  }\n",
    "  string_formula = paste0(string_formula, tmp_component)  \n",
    "}\n",
    "requested_formula = as.formula(string_formula)\n",
    "print(requested_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET ~ +rcs(Avg_EXT_SOURCE_application, 4) + rcs(ANNUITY_LENGTH, \n",
      "    4) + MAX_DAYS_CREDIT_bureau + rcs(CNT_INSTALMENT_FUTURE_min_sd_POS_CASH, \n",
      "    4) + rcs(MAX_DAYS_CREDIT_ENDDATE_bureau, 4) + CODE_GENDER + \n",
      "    rcs(CREDIT_TO_GOODS_RATIO, 4) + rcs(EXT_SOURCE_1.x, 4) + \n",
      "    rcs(EXT_SOURCE_2.x, 4) + rcs(EXT_SOURCE_3.x, 4)\n"
     ]
    }
   ],
   "source": [
    "# Mechanically create a formula for imputation\n",
    "\n",
    "col_set = M %>% names()\n",
    "col_set = col_set[!col_set %in% c(\"TARGET\", 'SK_ID_CURR', 'fold', 'Weights')]\n",
    "\n",
    "string_formula = \"TARGET~\"\n",
    "for(i in col_set){\n",
    "  if(class(M[[i]]) == \"numeric\"){\n",
    "    tmp_component = paste0(\"+rcs(\",i,\",4)\")\n",
    "  }\n",
    "  if(class(M[[i]]) != \"numeric\"){\n",
    "    tmp_component = paste0(\"+\",i)\n",
    "  }\n",
    "  string_formula = paste0(string_formula, tmp_component)  \n",
    "}\n",
    "requested_formula = as.formula(string_formula)\n",
    "print(requested_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Inf with NA as transcan, aregimpute cannot handle Inf\n",
    "system.time(invisible(lapply(names(M),function(.name) set(M, which(is.infinite(M[[.name]])), j = .name,value =NA))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions / Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. transcan and aregImpute cannot handle infinite values, need to first replace with NA. Use the following code.\n",
    "> system.time(invisible(lapply(names(M),function(.name) set(M, which(is.infinite(M[[.name]])), j = .name,value =NA))))\n",
    "    \n",
    "2. aregImpute more fault-tolerant than transcan, latter would quit if it does not converge in 50 iterations.\n",
    "> Error in transcan(~Avg_EXT_SOURCE_application + ANNUITY_LENGTH + MAX_DAYS_CREDIT_bureau + : no convergence in 50 iterations\n",
    "\n",
    "3. data.table::fread much better than read.csv for larger datasets, 2.5min vs 40min!\n",
    "\n",
    "4. Peek at the source code for R packages to understand how to use the dataset! (https://github.com/harrelfe/Hmisc/blob/master/R/fit.mult.impute.s)\n",
    "\n",
    "5. identical and all.equal can be used to check if two data frames are the same (https://stackoverflow.com/questions/10978895/how-to-compare-two-dataframes)\n",
    "\n",
    "6. fread and read.csv have different behaviors:\n",
    "   1. V1 vs X for the unnamed first column\n",
    "   2. train_imp[,c(1,3:ncol(train_imp),2)] would not reorder the column if read in by fread\n",
    "   3. DT[,feat_list] would look for a column named feat_list, need to use with=FALSE to use it as Data Frame\n",
    "   Check 1.1 in the FAQ\n",
    "   http://datatable.r-forge.r-project.org/datatable-faq.pdf\n",
    "   4. Need to convert Data Table back to Data Frame (using setDF(df)) before using the old-fashioned join, otherwise would get the following error:\n",
    "   > Error in `[.data.table`(x, i, which = TRUE): When i is a data.table (or character vector), the columns to join by must be specified either using 'on=' argument (see ?data.table) or by keying x (i.e. sorted, and, marked as sorted, see ?setkey). Keyed joins might have further speed benefits on very large data due to x being sorted in RAM.\n",
    "   \n",
    "7. R codes could be difficult to debug, could just tell you there is an error, but not the offending variables., e.g.:\n",
    "   1. NAs are not allowed in subscripted assignments???\n",
    "   \n",
    "8. After Multiple Imputation, my model seems way over-fitted, need to figure out the correct way to use it, as it doesn't seem as straightforward as I had originally expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

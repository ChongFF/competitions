{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Attaching package: ‘data.table’\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "Loading required package: Hmisc\n",
      "Loading required package: lattice\n",
      "Loading required package: survival\n",
      "Loading required package: Formula\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Attaching package: ‘Hmisc’\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    combine, src, summarize\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    format.pval, round.POSIXt, trunc.POSIXt, units\n",
      "\n",
      "Loading required package: SparseM\n",
      "\n",
      "Attaching package: ‘SparseM’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    backsolve\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data processing script\n",
    "# \n",
    "# assign working directory path\n",
    "wd.path <- \"~/in\"\n",
    "setwd(wd.path)\n",
    "set.seed(1234)\n",
    "library(dplyr)\n",
    "library(data.table)            # to get fread\n",
    "# library(foreach)\n",
    "# library(caret)\n",
    "# library(reshape2)\n",
    "library(rms)\n",
    "library(WeightedROC)\n",
    "\n",
    "#Sample mode function from Source: https://stackoverflow.com/questions/2547402/is-there-a-built-in-function-for-finding-the-mode\n",
    "Mode <- function(x, na.rm = FALSE) {\n",
    "  if (na.rm) {\n",
    "    x = x[!is.na(x)]\n",
    "  }\n",
    "  \n",
    "  ux <- unique(x)\n",
    "  return(ux[which.max(tabulate(match(x, ux)))])\n",
    "}\n",
    "\n",
    "imputationFunction <- function(imputeToData, imputeFromData, FUN, missingCols, suffix){\n",
    "  # imputeToData -  Imputation to be done on this data\n",
    "  # imputeFromData - Imputations calculation from this data\n",
    "  # FUN - imputation function\n",
    "  # missingCols - missing value column names\n",
    "  # suffix - suffix to add after column name\n",
    "  \n",
    "  imputeToData <- imputeToData[, names(imputeToData) %in% missingCols]\n",
    "  imputeFromData <- imputeFromData[, names(imputeFromData) %in% missingCols]\n",
    "  imputeVec <- apply(imputeFromData, 2, function(x) FUN(x, na.rm = T))\n",
    "  \n",
    "  for (i in 1:length(missingCols)) {\n",
    "    imputeToxData[is.na(imputeToData[, names(imputeToData) %in% missingCols[i]])\n",
    "                 , names(imputeToData) %in% missingCols[i]] <- imputeVec[names(imputeVec) %in% missingCols[i]]\n",
    "  }\n",
    "  \n",
    "  names(imputeToData) <- paste0(names(imputeToData), suffix)\n",
    "  return(imputeToData)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Processing: join in Weight and Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>test</dt>\n",
       "\t\t<dd>'1011.4 Mb'</dd>\n",
       "\t<dt>Mode</dt>\n",
       "\t\t<dd>'11.5 Kb'</dd>\n",
       "\t<dt>imputationFunction</dt>\n",
       "\t\t<dd>'21.6 Kb'</dd>\n",
       "\t<dt>missingCols</dt>\n",
       "\t\t<dd>'314.7 Kb'</dd>\n",
       "\t<dt>saveNames</dt>\n",
       "\t\t<dd>'323.5 Kb'</dd>\n",
       "\t<dt>train</dt>\n",
       "\t\t<dd>'6.2 Gb'</dd>\n",
       "\t<dt>wd.path</dt>\n",
       "\t\t<dd>'96 bytes'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[test] '1011.4 Mb'\n",
       "\\item[Mode] '11.5 Kb'\n",
       "\\item[imputationFunction] '21.6 Kb'\n",
       "\\item[missingCols] '314.7 Kb'\n",
       "\\item[saveNames] '323.5 Kb'\n",
       "\\item[train] '6.2 Gb'\n",
       "\\item[wd.path] '96 bytes'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "test\n",
       ":   '1011.4 Mb'Mode\n",
       ":   '11.5 Kb'imputationFunction\n",
       ":   '21.6 Kb'missingCols\n",
       ":   '314.7 Kb'saveNames\n",
       ":   '323.5 Kb'train\n",
       ":   '6.2 Gb'wd.path\n",
       ":   '96 bytes'\n",
       "\n"
      ],
      "text/plain": [
       "              test               Mode imputationFunction        missingCols \n",
       "       \"1011.4 Mb\"          \"11.5 Kb\"          \"21.6 Kb\"         \"314.7 Kb\" \n",
       "         saveNames              train            wd.path \n",
       "        \"323.5 Kb\"           \"6.2 Gb\"         \"96 bytes\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find out the memory usage of each item\n",
    "sort(sapply(ls(), function(x) format(object.size(get(x)), unit = 'auto')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"2018-08-28 12:58:46 UTC\"\n",
      "Read 307511 rows and 3205 (of 3205) columns from 4.639 GB file in 00:01:53\n",
      "Read 48744 rows and 3202 (of 3202) columns from 0.751 GB file in 00:00:15\n",
      "[1] \"2018-08-28 13:00:53 UTC\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>  2216381 </td><td> 118.4    </td><td>   3886542</td><td> 207.6    </td><td>  2637877 </td><td> 140.9    </td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>972410063 </td><td>7419.0    </td><td>1227364503</td><td>9364.1    </td><td>981527564 </td><td>7488.5    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &   2216381  &  118.4     &    3886542 &  207.6     &   2637877  &  140.9    \\\\\n",
       "\tVcells & 972410063  & 7419.0     & 1227364503 & 9364.1     & 981527564  & 7488.5    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) | \n",
       "|---|---|\n",
       "| Ncells |   2216381  |  118.4     |    3886542 |  207.6     |   2637877  |  140.9     | \n",
       "| Vcells | 972410063  | 7419.0     | 1227364503 | 9364.1     | 981527564  | 7488.5     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "       used      (Mb)   gc trigger (Mb)   max used  (Mb)  \n",
       "Ncells   2216381  118.4    3886542  207.6   2637877  140.9\n",
       "Vcells 972410063 7419.0 1227364503 9364.1 981527564 7488.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Sys.time())\n",
    "train <- fread('train_modified.csv') # applications test data\n",
    "test <- fread('test_modified.csv') # applications train data\n",
    "print(Sys.time())\n",
    "\n",
    "# storing column names for later\n",
    "saveNames <- names(train)\n",
    "\n",
    "# columns with missing values\n",
    "missingCols <-  names(train)[apply(train, 2, function(x) sum(is.na(x))) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(missingCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(head(train$Weights))\n",
    "print(head(train$fold))\n",
    "# already there no need to load the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mechanically create a formula for imputation\n",
    "M = train\n",
    "\n",
    "col_set = M %>% names()\n",
    "col_set = col_set[!col_set %in% \"TARGET\"]\n",
    "\n",
    "string_formula = \"TARGET~\"\n",
    "for(i in col_set){\n",
    "  if(class(M[[i]]) == \"numeric\"){\n",
    "    tmp_component = paste0(\"+\",i)\n",
    "  }\n",
    "  if(class(M[[i]]) != \"numeric\"){\n",
    "    tmp_component = paste0(\"+\",i)\n",
    "  }\n",
    "  string_formula = paste0(string_formula, tmp_component)  \n",
    "}\n",
    "requested_formula = as.formula(string_formula)\n",
    "requested_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na.patterns <- naclus(train)\n",
    "naplot(na.patterns, 'na per var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually convert some of the 'Unknown' levels to NA\n",
    "train_imp = train\n",
    "train_imp[train_imp == 'XNA' | train_imp == 'Unknown'] <- NA\n",
    "train_imp = droplevels(train_imp)\n",
    "\n",
    "# Code example to see the use of dropLevels, dropping factor level with no observation\n",
    "# train2 <- subset(train_imp, select= c(CODE_GENDER, NAME_FAMILY_STATUS))\n",
    "# str(train2)\n",
    "# train2 = droplevels(train2)\n",
    "# str(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imp_small <- train[1:5, c('TARGET','NAME_CONTRACT_TYPE','CODE_GENDER',\n",
    "    'FLAG_OWN_CAR','FLAG_OWN_REALTY','CNT_CHILDREN','AMT_INCOME_TOTAL',\n",
    "    'AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE','NAME_TYPE_SUITE',\n",
    "    'NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS',\n",
    "    'NAME_HOUSING_TYPE','REGION_POPULATION_RELATIVE','DAYS_BIRTH',\n",
    "    'DAYS_EMPLOYED','DAYS_REGISTRATION','DAYS_ID_PUBLISH','OWN_CAR_AGE',\n",
    "    'FLAG_MOBIL','FLAG_EMP_PHONE')]\n",
    "train_imp_small[train_imp_small == 'XNA' | train_imp_small == 'Unknown'] <- NA\n",
    "train_imp_small = droplevels(train_imp_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(17) # so can reproduce random aspects\n",
    "mi <- aregImpute(~ TARGET + NAME_CONTRACT_TYPE + CODE_GENDER + \n",
    "    #FLAG_OWN_CAR + \n",
    "                 FLAG_OWN_REALTY + CNT_CHILDREN + AMT_INCOME_TOTAL + \n",
    "    AMT_CREDIT + AMT_ANNUITY + AMT_GOODS_PRICE + NAME_TYPE_SUITE + \n",
    "    #NAME_INCOME_TYPE + \n",
    "                 NAME_EDUCATION_TYPE + NAME_FAMILY_STATUS + \n",
    "    NAME_HOUSING_TYPE + REGION_POPULATION_RELATIVE + DAYS_BIRTH + \n",
    "    DAYS_EMPLOYED + DAYS_REGISTRATION + DAYS_ID_PUBLISH + OWN_CAR_AGE + \n",
    "    FLAG_MOBIL + FLAG_EMP_PHONE + FLAG_WORK_PHONE + FLAG_CONT_MOBILE + \n",
    "    FLAG_PHONE + FLAG_EMAIL + OCCUPATION_TYPE + CNT_FAM_MEMBERS, data=train_imp, n.impute=10, nk=4, pr=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " + \n",
    "    REGION_RATING_CLIENT + REGION_RATING_CLIENT_W_CITY + WEEKDAY_APPR_PROCESS_START + \n",
    "    HOUR_APPR_PROCESS_START + REG_REGION_NOT_LIVE_REGION + REG_REGION_NOT_WORK_REGION + \n",
    "    LIVE_REGION_NOT_WORK_REGION + REG_CITY_NOT_LIVE_CITY + REG_CITY_NOT_WORK_CITY + \n",
    "    LIVE_CITY_NOT_WORK_CITY + ORGANIZATION_TYPE + EXT_SOURCE_1 + \n",
    "    EXT_SOURCE_2 + EXT_SOURCE_3 + APARTMENTS_AVG + BASEMENTAREA_AVG + \n",
    "    YEARS_BEGINEXPLUATATION_AVG + YEARS_BUILD_AVG + COMMONAREA_AVG + \n",
    "    ELEVATORS_AVG + ENTRANCES_AVG + FLOORSMAX_AVG + FLOORSMIN_AVG + \n",
    "    LANDAREA_AVG + LIVINGAPARTMENTS_AVG + LIVINGAREA_AVG + NONLIVINGAPARTMENTS_AVG + \n",
    "    NONLIVINGAREA_AVG + APARTMENTS_MODE + BASEMENTAREA_MODE + \n",
    "    YEARS_BEGINEXPLUATATION_MODE + YEARS_BUILD_MODE + COMMONAREA_MODE + \n",
    "    ELEVATORS_MODE + ENTRANCES_MODE + FLOORSMAX_MODE + FLOORSMIN_MODE + \n",
    "    LANDAREA_MODE + LIVINGAPARTMENTS_MODE + LIVINGAREA_MODE + \n",
    "    NONLIVINGAPARTMENTS_MODE + NONLIVINGAREA_MODE + APARTMENTS_MEDI + \n",
    "    BASEMENTAREA_MEDI + YEARS_BEGINEXPLUATATION_MEDI + YEARS_BUILD_MEDI + \n",
    "    COMMONAREA_MEDI + ELEVATORS_MEDI + ENTRANCES_MEDI + FLOORSMAX_MEDI + \n",
    "    FLOORSMIN_MEDI + LANDAREA_MEDI + LIVINGAPARTMENTS_MEDI + \n",
    "    LIVINGAREA_MEDI + NONLIVINGAPARTMENTS_MEDI + NONLIVINGAREA_MEDI + \n",
    "    FONDKAPREMONT_MODE + HOUSETYPE_MODE + TOTALAREA_MODE + WALLSMATERIAL_MODE + \n",
    "    EMERGENCYSTATE_MODE + OBS_30_CNT_SOCIAL_CIRCLE + DEF_30_CNT_SOCIAL_CIRCLE + \n",
    "    OBS_60_CNT_SOCIAL_CIRCLE + DEF_60_CNT_SOCIAL_CIRCLE + DAYS_LAST_PHONE_CHANGE + \n",
    "    FLAG_DOCUMENT_2 + FLAG_DOCUMENT_3 + FLAG_DOCUMENT_4 + FLAG_DOCUMENT_5 + \n",
    "    FLAG_DOCUMENT_6 + FLAG_DOCUMENT_7 + FLAG_DOCUMENT_8 + FLAG_DOCUMENT_9 + \n",
    "    FLAG_DOCUMENT_10 + FLAG_DOCUMENT_11 + FLAG_DOCUMENT_12 + \n",
    "    FLAG_DOCUMENT_13 + FLAG_DOCUMENT_14 + FLAG_DOCUMENT_15 + \n",
    "    FLAG_DOCUMENT_16 + FLAG_DOCUMENT_17 + FLAG_DOCUMENT_18 + \n",
    "    FLAG_DOCUMENT_19 + FLAG_DOCUMENT_20 + FLAG_DOCUMENT_21 + \n",
    "    AMT_REQ_CREDIT_BUREAU_HOUR + AMT_REQ_CREDIT_BUREAU_DAY + \n",
    "    AMT_REQ_CREDIT_BUREAU_WEEK + AMT_REQ_CREDIT_BUREAU_MON + \n",
    "    AMT_REQ_CREDIT_BUREAU_QRT + AMT_REQ_CREDIT_BUREAU_YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test <- read.csv('application_test.csv') # applications test data\n",
    "train <- read.csv('application_train.csv') # applications train data\n",
    "\n",
    "# storing column names for later\n",
    "saveNames <- names(train)\n",
    "\n",
    "# columns with missing values\n",
    "missingCols <-  names(train)[apply(train, 2, function(x) sum(is.na(x))) > 0]\n",
    "                                   \n",
    "#train imputation\n",
    "medianDatatr <- imputationFunction(imputeToData = train, imputeFromData = train, FUN = median\n",
    "                                   , missingCols = missingCols, suffix = '.trmedian')\n",
    "\n",
    "#test imputation\n",
    "medianDatatst.tst <- imputationFunction(imputeToData = test, imputeFromData = test, FUN = median\n",
    "                                    , missingCols = missingCols, suffix = '.tstmedian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Transformation to get to the Imputed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights <- read.csv('Weights_and_fold.csv')\n",
    "print(\"Weights loaded\")\n",
    "train <- cbind(train, medianDatatr) %>% left_join(weights, by = \"SK_ID_CURR\")\n",
    "write.csv(train,'application_train_imp.csv')\n",
    "test <- cbind(test, medianDatatst.tst)\n",
    "write.csv(test,'application_test_imp.csv')\n",
    "rm(medianDatatr, medianDatatst.tst, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights <- read.csv('V2_weight_R_code(Alex)/Train_Weights_V2.csv')\n",
    "train <- read.csv('application_train_imp.csv') # applications train data\n",
    "train <- train %>% select(-Weights, -X) %>% left_join(weights, by = \"SK_ID_CURR\") %>% select(-X)\n",
    "write.csv(train,'application_train_imp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here for Subsequent Runs, read in the processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test <- read.csv('application_test_imp.csv') # applications test data\n",
    "train <- read.csv('application_train_imp.csv') # applications train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mechanically create a formula for rms modeling\n",
    "M = train\n",
    "\n",
    "col_set = M %>% names()\n",
    "col_set = col_set[!col_set %in% \"TARGET\"]\n",
    "\n",
    "string_formula = \"TARGET~\"\n",
    "for(i in col_set){\n",
    "  if(class(M[[i]]) == \"numeric\"){\n",
    "    tmp_component = paste0(\"+rcs(\",i,\",3)\")\n",
    "  }\n",
    "  if(class(M[[i]]) != \"numeric\"){\n",
    "    tmp_component = paste0(\"+\",i)\n",
    "  }\n",
    "  string_formula = paste0(string_formula, tmp_component)  \n",
    "}\n",
    "requested_formula = as.formula(string_formula)\n",
    "requested_formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model + AMT_CREDIT (Model FF_rms_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform 5 fold cross validation\n",
    "model = list()\n",
    "mod_anova = list()\n",
    "test_roc = list()\n",
    "\n",
    "for(i in 1:5){\n",
    "    testData <- train[train$fold==i,]\n",
    "    trainData <- train[train$fold!=i,]\n",
    "    string_formula <- TARGET ~ NAME_CONTRACT_TYPE + CODE_GENDER + FLAG_OWN_CAR + FLAG_OWN_REALTY + rcs(EXT_SOURCE_1.trmedian, 4) + \n",
    "            rcs(EXT_SOURCE_2.trmedian, 4) + rcs(EXT_SOURCE_3.trmedian,4) + rcs(AMT_CREDIT, 3)\n",
    "    requested_formula = as.formula(string_formula)\n",
    "    a_model = lrm(data=trainData, formula = requested_formula, weight=Weights, tol=1E-10, x=TRUE,y=TRUE)\n",
    "        \n",
    "    # diagnostic plots\n",
    "    ## Variable Importance\n",
    "    mod_anova[[i]] <- anova(a_model)\n",
    "    \n",
    "    ## Validation Statistics\n",
    "    print(validate(a_model, B=10))\n",
    "    model[[i]] <- a_model\n",
    "\n",
    "    ## Calibration Curve\n",
    "    # plot(calibrate(a_model, B=10))\n",
    "\n",
    "    # use a fitted model to score a dataset, convert score to probability\n",
    "    test_scored <- cbind(testData, predict(a_model, testData, se.fit=TRUE))\n",
    "    test_scored$pred = exp(test_scored$linear.predictors)/(1+exp(test_scored$linear.predictors))\n",
    "\n",
    "    # Weighted AUROC\n",
    "    tp.fp <- WeightedROC(test_scored$pred,test_scored$TARGET,test_scored$Weights)\n",
    "    test_roc[[i]] <- WeightedAUC(tp.fp)\n",
    "    print(test_roc[[i]])\n",
    "\n",
    "    # Unweighted AUROC\n",
    "    tp.fp <- WeightedROC(test_scored$pred,test_scored$TARGET)\n",
    "    print(WeightedAUC(tp.fp))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Perform 5 fold cross validation\n",
    "model = list()\n",
    "mod_anova = list()\n",
    "test_roc = list()\n",
    "\n",
    "for(i in 1:5){\n",
    "    testData <- train[train$fold==i,]\n",
    "    trainData <- train[train$fold!=i,]\n",
    "    string_formula <- TARGET ~ NAME_CONTRACT_TYPE + CODE_GENDER + FLAG_OWN_CAR + FLAG_OWN_REALTY + rcs(EXT_SOURCE_1.trmedian, 4) + \n",
    "            rcs(EXT_SOURCE_2.trmedian, 4) + rcs(EXT_SOURCE_3.trmedian,4)\n",
    "    requested_formula = as.formula(string_formula)\n",
    "    a_model = lrm(data=trainData, formula = requested_formula, weight=Weights, tol=1E-10, x=TRUE,y=TRUE)\n",
    "        \n",
    "    # diagnostic plots\n",
    "    ## Variable Importance\n",
    "    mod_anova[[i]] <- anova(a_model)\n",
    "    \n",
    "    ## Validation Statistics\n",
    "    print(validate(a_model, B=10))\n",
    "    model[[i]] <- a_model\n",
    "\n",
    "    ## Calibration Curve\n",
    "    # plot(calibrate(a_model, B=10))\n",
    "\n",
    "    # use a fitted model to score a dataset, convert score to probability\n",
    "    test_scored <- cbind(testData, predict(a_model, testData, se.fit=TRUE))\n",
    "    test_scored$pred = exp(test_scored$linear.predictors)/(1+exp(test_scored$linear.predictors))\n",
    "\n",
    "    # Weighted AUROC\n",
    "    tp.fp <- WeightedROC(test_scored$pred,test_scored$TARGET,test_scored$Weights)\n",
    "    test_roc[[i]] <- WeightedAUC(tp.fp)\n",
    "    print(test_roc[[i]])\n",
    "\n",
    "    # Unweighted AUROC\n",
    "    tp.fp <- WeightedROC(test_scored$pred,test_scored$TARGET)\n",
    "    print(WeightedAUC(tp.fp))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to understand why adding AMT_CREDIT, AMT_INCOME_TOTAL to the model would cause information matrix singularity\n",
    "train_samp_col <- train %>% select(AMT_CREDIT, AMT_INCOME_TOTAL)\n",
    "hist(train_samp_col)\n",
    "# the value seems pretty ordinary\n",
    "\n",
    "cor(trainData[,c(\"EXT_SOURCE_1.trmedian\", \"EXT_SOURCE_2.trmedian\", \"EXT_SOURCE_3.trmedian\", \"AMT_CREDIT\", \"AMT_INCOME_TOTAL\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FF_rms_2 on the full dataset and create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_formula <- TARGET ~ NAME_CONTRACT_TYPE + CODE_GENDER + FLAG_OWN_CAR + FLAG_OWN_REALTY + rcs(EXT_SOURCE_1.trmedian, 4) + \n",
    "            rcs(EXT_SOURCE_2.trmedian, 4) + rcs(EXT_SOURCE_3.trmedian,4) + rcs(AMT_CREDIT, 3)\n",
    "requested_formula = as.formula(string_formula)\n",
    "a_model = lrm(data=train, formula = requested_formula, weight=Weights, tol=1E-10, x=TRUE,y=TRUE)\n",
    "\n",
    "# Diagnostic Plots\n",
    "## Variable Importance\n",
    "plot(anova(a_model))\n",
    "## Partial Effect Plot\n",
    "dd <- datadist(train); options(datadist='dd')\n",
    "ggplot(Predict(a_model),sepdiscrete='vertical',vnames='names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test$EXT_SOURCE_1.trmedian = test$EXT_SOURCE_1.tstmedian\n",
    "test$EXT_SOURCE_2.trmedian = test$EXT_SOURCE_2.tstmedian\n",
    "test$EXT_SOURCE_3.trmedian = test$EXT_SOURCE_3.tstmedian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scored <- cbind(test, predict(a_model, test, se.fit=TRUE))\n",
    "test_scored$TARGET <- exp(test_scored$linear.predictors)/(1+exp(test_scored$linear.predictors))\n",
    "submission <- test_scored %>% select(SK_ID_CURR, TARGET)\n",
    "write.csv(submission, \"test_scored.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

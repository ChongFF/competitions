{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Imports complete-----\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import pickle as pickle\n",
    "import os.path\n",
    "\n",
    "import scipy\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from PIL import Image\n",
    "print(\"------Imports complete-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "train_path = \"/media/alex/B44254FE4254C730/Users/Alex/Downloads/Kaggle Data/train-jpg/train-jpg/\"\n",
    "test_path = \"/media/alex/B44254FE4254C730/Users/Alex/Downloads/Kaggle Data/test-jpg/\"\n",
    "\n",
    "train = pd.read_csv(\"/home/alex/Desktop/Rainforest/Data/train_v2.csv\")\n",
    "test =  pd.read_csv(\"/home/alex/Desktop/Rainforest/Data/sample_submission_v2.csv\")\n",
    "#Location for saving serialized objects\n",
    "obj_save_path = \"/home/alex/Desktop/Rainforest/Models/XGB/Objects/\"\n",
    "subm_output_path = \"/home/alex/Desktop/Rainforest/Submissions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature-Extraction Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df, data_path):\n",
    "\t#create a copy of original panda dataframe so that extracted features can be added.\n",
    "\tim_features = df.copy()\n",
    "\tr_mean = []\n",
    "\tg_mean = []\n",
    "\tb_mean = []\n",
    "\n",
    "\tr_std=[]\n",
    "\tg_std=[]\n",
    "\tb_std=[]\n",
    "\n",
    "\tr_max=[]\n",
    "\tg_max=[]\n",
    "\tb_max=[]\n",
    "\t\n",
    "\tr_min=[]\n",
    "\tg_min=[]\n",
    "\tb_min=[]\n",
    "\n",
    "\tr_kurtosis=[]\n",
    "\tg_kurtosis=[]\n",
    "\tb_kurtosis=[]\n",
    "\n",
    "\tr_skewness=[]\n",
    "\tg_skewness=[]\n",
    "\tb_skewness=[]\n",
    "\n",
    "\tfor image_name in tqdm(im_features.image_name.values, miniters=1000):\n",
    "\t\t\n",
    "\t\tif \"file_\" in image_name:\n",
    "\t\t\tcontinue \n",
    "\t\tim = Image.open(data_path + image_name + '.jpg')\n",
    "\t\t#creating 256x256x3 array\n",
    "\t\tim= np.array(im)[:,:,:3]\n",
    "\t\t\n",
    "\t\t# im[:,:,0] has dimension 256x256; .ravel() flattens into 256^2 x 1\n",
    "\t\tr = im[:,:,0].ravel()\n",
    "\t\tg = im[:,:,1].ravel()\n",
    "\t\tb = im[:,:,2].ravel()\n",
    "\t\t\n",
    "\t\tr_mean.append(np.mean(r))\n",
    "\t\tg_mean.append(np.mean(g))\n",
    "\t\tb_mean.append(np.mean(b))\n",
    "\n",
    "\t\tr_std.append(np.std(r))\n",
    "\t\tg_std.append(np.std(g))\n",
    "\t\tb_std.append(np.std(b))\n",
    "\n",
    "\t\tr_max.append(np.max(r))\n",
    "\t\tg_max.append(np.max(g))\n",
    "\t\tb_max.append(np.max(b))\n",
    "\t\t\n",
    "\t\tr_min.append(np.min(r))\n",
    "\t\tg_min.append(np.min(g))\n",
    "\t\tb_min.append(np.min(b))\n",
    "\t\t\n",
    "\t\tr_kurtosis.append(scipy.stats.kurtosis(r))\n",
    "\t\tg_kurtosis.append(scipy.stats.kurtosis(g))\n",
    "\t\tb_kurtosis.append(scipy.stats.kurtosis(b))\n",
    "\t\t\n",
    "\t\tr_skewness.append(scipy.stats.skew(r))\n",
    "\t\tg_skewness.append(scipy.stats.skew(g))\n",
    "\t\tb_skewness.append(scipy.stats.skew(b))\n",
    "\n",
    "\t#Add extracted features to pandas frame\n",
    "\t#print(im_features['r_mean'].shape)\n",
    "\t#print(r_mean.shape)\n",
    "\tim_features['r_mean'] = r_mean\n",
    "\tim_features['g_mean'] = g_mean\n",
    "\tim_features['b_mean'] = b_mean\n",
    "\t\n",
    "\tim_features['r_std'] = r_std\n",
    "\tim_features['g_std'] = g_std\n",
    "\tim_features['b_std'] = b_std\n",
    "\t\n",
    "\tim_features['r_max'] = r_max\n",
    "\tim_features['g_max'] = g_max\n",
    "\tim_features['b_max'] = b_max\n",
    "\t\n",
    "\tim_features['r_min'] = r_min\n",
    "\tim_features['g_min'] = g_min\n",
    "\tim_features['b_min'] = b_min\n",
    "\t\n",
    "\tim_features['r_kurtosis'] = r_kurtosis\n",
    "\tim_features['g_kurtosis'] = g_kurtosis\n",
    "\tim_features['b_kurtosis'] = b_kurtosis\n",
    "\t\n",
    "\tim_features['r_skewness'] = r_skewness\n",
    "\tim_features['g_skewness'] = g_skewness\n",
    "\tim_features['b_skewness'] = b_skewness\n",
    "\t\n",
    "\t#return a pandas dataframe with above features extracted\n",
    "\treturn im_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---train_features successfully loaded---\n"
     ]
    }
   ],
   "source": [
    "#Check for saved objects.  If not found extract features.\n",
    "if(os.path.isfile(obj_save_path + \"train_features.p\")):\n",
    "    #Try loading frame, if fails then re-extract.\n",
    "    try:\n",
    "        file = open(obj_save_path + \"train_features.p\",'rb')\n",
    "        train_features = pickle.load(file)\n",
    "        file.close()\n",
    "        print(\"---train_features successfully loaded---\")\n",
    "    except:\n",
    "        print(\"---loading of train_features failed--\")\n",
    "        train_features = extract_features(train,train_path)\n",
    "        pickle.dump(train_features, open(obj_save_path + 'train_features.p','wb'))\n",
    "else:\n",
    "    print(\"train_features.p not found-- training model\")\n",
    "    train_features = extract_features(train,train_path)\n",
    "    pickle.dump(train_features, open(obj_save_path + 'train_features.p','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test features\n",
      "---test_features successfully loaded---\n"
     ]
    }
   ],
   "source": [
    "#Extract features on test set:\n",
    "print('Extracting test features')\n",
    "\n",
    "if(os.path.isfile(obj_save_path + \"test_features.p\")):\n",
    "    try:\n",
    "        file = open(obj_save_path + \"test_features.p\",'rb')\n",
    "        test_features = pickle.load(file)\n",
    "        file.close()\n",
    "        print(\"---test_features successfully loaded---\")\n",
    "    except:\n",
    "        print(\"---loading of test_features failed--\")\n",
    "        test_features = extract_features(test,test_path)\n",
    "        pickle.dump(test_features, open(obj_save_path + 'test_features.p','wb'))\n",
    "\n",
    "else:\n",
    "    print(\"test_features.p not found-- extracting features\")\n",
    "    test_features = extract_features(test,test_path)\n",
    "    pickle.dump(test_features, open(obj_save_path + 'test_features.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Drop labels, keep only predictors.  Result is 40479 x 18 matrix\n",
    "X = np.array(train_features.drop(['image_name','tags'],axis = 1))\n",
    "y_train = []\n",
    "\n",
    "#Define a function 'flatten'\n",
    "#Very clever way to to take a list of lists and convert to a simple list\n",
    "#e.g. from [[1,2],[3,4]] --> [1,2,3,4] \n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "#Go through each observation, gather all tags, get all unique values\n",
    "tmp = []\n",
    "for l in train_features['tags'].values:\n",
    "    tmp.append(l.split(' '))\n",
    "    \n",
    "labels = np.array(list(set(flatten(tmp))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dictionary of labels\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following for-loop creates an nx17 binary indicator matrix for the 17 possible labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 196931.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for tags in tqdm(train.tags.values, miniters = 1000):\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1\n",
    "    y_train.append(targets)\n",
    "\n",
    "#Convert python list to numpy array.\n",
    "#np.uint8 is data type: unsigned 8-bit integer\n",
    "y = np.array(y_train, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (40479, 18)\n",
      "y.shape = (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "#X.shape gives extracted features in observation matrix\n",
    "print('X.shape = ' + str(X.shape))\n",
    "#y.shape gives number of possible labels\n",
    "print('y.shape = ' + str(y.shape))\n",
    "\n",
    "#set classes to 17\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "X_test = np.array(test_features.drop(['image_name','tags'], axis = 1))\n",
    "\n",
    "#Create a null matrix of prediction count x 17\n",
    "y_pred = np.zeros((X_test.shape[0], n_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train All 17 Models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:38<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "for class_i in tqdm( range(n_classes), miniters = 1 ):\n",
    "    model = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=100, \\\n",
    "                              silent=True, objective='binary:logistic', nthread=-1, \\\n",
    "                              gamma=0, min_child_weight=1, max_delta_step=0, \\\n",
    "                              subsample=1, colsample_bytree=1, colsample_bylevel=1, \\\n",
    "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \\\n",
    "                              base_score=0.5, seed=random_seed, missing=None)\n",
    "    model.fit(X, y[:, class_i])\n",
    "    #Apply model i\n",
    "    y_pred[:,class_i] = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = [' '.join(labels[y_pred_row > 0.21]) for y_pred_row in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Arbitrary cutoff of .21 imposed-- I have no idea why this number is chosen.\n",
    "preds = [' '.join(labels[y_pred_row > 0.21]) for y_pred_row in y_pred]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build submission file\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = test_features.image_name.values\n",
    "subm['tags'] = preds\n",
    "subm.to_csv(str(subm_output_path + 'submission.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
